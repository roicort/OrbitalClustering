% !TEX root = ../my-thesis.tex
%
\chapter{Método propuesto}
\label{sec:proposal}

%\cleanchapterquote{Innovation distinguishes between a leader and a follower.}{Steve Jobs}{(CEO Apple Inc.)}

El agrupamiento de una colección de grafos no es un problema sencillo. El uso de algoritmos de agrupación populares, como K-Means, requiere representar los grafos en un espacio vectorial. Esta tarea puede llevarse a cabo mediante métodos que van desde la extracción de características - por ejemplo graphlets - hasta \textit{embeddings} más sofisticados generados a través de redes neuronales. 

Priorizando la interpretación de los resultados, proponemos usar el conteo de órbitas en graphlets dirigidos para hacer una caracterización de los usuarios en la colección analizada y crear un \textit{embedding} de las redes que brinde información sobre el tipo de comportamiento que genera un determinado tema. 

En este capítulo se presenta un método para agrupar redes a través de la firma orbital de sus nodos y que, así, toma en cuenta los roles estructurales de los usuarios. El método tiene dos etapas principales. Primero construye perfiles de usuarios utilizando la firma de la órbita asignada a cada nodo en un análisis de la red basado en graphlets. Después, agrupa las redes con base en la distribución de perfiles que presentan. 

\section{Graphlets y órbitas dirigidas}

A partir de los conteos de órbitas vistos en el capítulo anterior, Sarajilic \textit{et al.} propusieron extender las órbitas a grafos dirigidos \cite{sarajlic_graphlet-based_2016}. Dada la cantidad de posibles configuraciones para las órbitas en un graphlet dirigido, los autores limitan el conteo a graphlets de hasta 4 nodos. En este caso, la firma orbital resultante para cada nodo es un vector en $R^{129}$ donde el componente $i$ representa el conteo de la órbita $i$, de acuerdo a la descripción presentada en la Fig. \ref{fig:orbits}.

 \begin{figure}[htbp]
   \centering
   \includesvg[width=0.9\textwidth]{figures/orbits.svg}
    \caption{Órbitas de hasta 4 nodos. $G_i$ representa un graphlet en la colección; las órbitas dentro de cada graphlet están ennumeradas para futuras referencias en este trabajo. }
    \label{fig:orbits}
\end{figure}


\section{Perfilar usuarios}
\label{sec:proposal:users}

 La creación de perfiles de usuario (\textit{user profiling}) ha tenido numerosas aplicaciones dentro y fuera de las ciencias computacionales. Existen metodologías que permiten encontrar perfiles de usuario a partir de minería de datos en redes sociales, de modo que los perfiles representan ciertos rasgos psicológicos con sus conductas asociadas y permiten, entre otras cosas, campañas de marketing dirigidas \cite{hu_cambridge_2020}. Estos métodos para crear perfiles o grupos de usuarios comúnmente se basan en los metadatos de las interacciones entre usuarios.
 
Como se ilustró en la sección \ref{section:nodeclustering}, es posible realizar agrupamientos en una red basados en los diversos roles estructurales de los nodos que la componen. Esta tarea nos permite agrupar los distintos comportamientos de los usuarios a partir del papel que desempeñan y, por lo tanto, crear perfiles de usuarios con comportamientos y funciones en la red similares.
 
En las redes sociales, específicamente en Twitter, las funciones y las interacciones que realiza un nodo dentro de una red inciden directamente en la composición y topología de la misma. Estudiar roles estructurales permite caracterizar nodos de acuerdo a su función, obtener información sobre los tipos de comportamiento de los usuarios y estudiar la composición de la red.

De hecho, diferentes trabajos en ciencias sociales se centran en los patrones de asociación en una red para entender los procesos dentro de un sistema. Por ejemplo, Lusher y Robins sugieren la presencia de configuraciones a lo largo de las líneas de "huellas arqueológicas" impresas en los mecanismos sociales a través del tiempo y ejemplifican su idea sugiriendo los arreglos mostrados en la Fig. \ref{fig:lusher}.

\begin{figure}[htbp]
  \centering
  \includesvg[width=1.\textwidth]{figures/LusherUnderstanding.svg}
    \caption{Algunos patrones propuestos por Lusher y Robins para describir configuraciones sociales dentro de procesos colectivos \citep{lusher_exponential_nodate}. Las aristas dirigidas permiten la distinción entre jerarquías y posiciones de poder dentro de la red.}
    \label{fig:lusher}
\end{figure}

Una propuesta importante de esta tesis es que, en el contexto de redes sociales, la firma orbital basada en graphlets que puede obtenerse para un nodo, podría analizarse como extensión del trabajo de Lusher y Robins. Es decir, proponemos considerar estructuras que van más allá de las triadas de usuarios, con el fin de capturar información sobre las dinámicas sociales, la jerarquía que se establece entre personas y la estructura general de la red. 

Así, consideramos que en el caso de Twitter es posible identificar perfiles de usuarios similares dentro de las redes temáticas. Debido a la capacidad de las órbitas de capturar información sobre las posiciones y roles estructurales de un nodo dentro de una red, proponemos agrupar los nodos (usuarios) de la red temática utilizando la firma orbital como un \textit{embedding} para crear perfiles de usuarios.

Las redes temáticas de Twitter son redes con aristas dirigidas. En el estudio propuesto de las órbitas, consideramos aquellas que aparecen en graphlets de orden 2-4, de acuerdo al trabajo de Sarajilic \textit{et al.} descrito en la sección anterior.  Por lo tanto, al realizar el conteo de órbitas dirigidas para cada nodo, se obtiene una matriz $M$ de tamaño $n_{users}\times 129$, en donde cada fila representa un nodo en la red. 

%[PÁRRAFO QUE TERMINA HABLANDO SOBRE EL VOLUMEN QUE SE ESPERA, Y POR QUÉ SERÍA NECESARIO UTILIZAR UNA VARIANTE MÁS EFICIENTE DE K-MEANS (MOTIVAR LA SIGUIENTE SUBSECCIÓN)]

Identificar los distintos perfiles a partir de la matriz $M$ requiere una tarea de agrupamiento. 
Aunque K-Means (Algoritmo \ref{algorithms:k-means}) es conveniente por motivos como la interpretabilidad, el volumen de datos en nuestro problema demanda un método más eficiente, considerando que se desea analizar la representación vectorial de todos los usuarios en todas las redes en la colección. Por esta razón, proponemos el uso de MiniBatch K-Means \cite{sculley_web-scale_2010}, que es una de las distintas modificaciones de K-Means propuestas para lidiar con limitaciones de tiempo y memoria. El algoritmo se describe a continuación. 

\subsection{MiniBatch K-Means}
A pesar de la enorme popularidad de K-Means por su simplicidad y buen desempeño, el algoritmo se ve limitado frente a la cada vez más grande cantidad de datos a analizar. Esto se debe a restricciones como tener que mantener todo el conjunto de datos en memoria. 

MiniBatch K-Means \cite{sculley_web-scale_2010} es una versión modificada de K-Means que busca reducir la complejidad computacional del algoritmo original utilizando únicamente una fracción del conjunto de datos en cada iteración. Esta estrategia reduce el número de cálculos de distancias por iteración y por lo tanto la complejidad total, pero con un costo asociado de un agrupamiento de menor calidad \cite{bejar_k-means_nodate}.

La idea principal de MiniBatch K-Means es utilizar pequeños lotes (mini batches) aleatorios de un tamaño fijo del conjunto de datos para poder almacenarlos en la memoria. En cada iteración se obtiene una nueva muestra aleatoria del conjunto de datos y se utiliza para actualizar los grupos (clusters) hasta la convergencia. 

MiniBatch K-Means hace uso de una tasa de aprendizaje que disminuye con el número de iteraciones. La tasa de aprendizaje es inversa del número de ejemplos asignados a un grupo durante el proceso y por lo tanto a medida que aumenta el número de iteraciones se reduce el efecto de nuevos ejemplos. La convergencia del algoritmo se puede detectar cuando no se producen más cambios en los grupos durante un número definido de iteraciones continuas. 

%[HACER REFERENCIA AL PSEUDOCódigo]

El Algoritmo \ref{algorithms:minik-means} muestra el pseudocódigo de MiniBatch K-Means y sus particularidades, entre ellas el muestreo $M$ de ejemplos aleatorios y el cálculo de la función objetivo (distorsión).

\lstinputlisting[language=Python, caption={Pseudocódigo $MiniBatch K-Means$ \cite{bejar_k-means_nodate}}\label{algorithms:minik-means}]{codes/minikmeans.pseudo} 

\subsection{Análisis de los perfiles identificados}
Para caracterizar el rol de los usuarios, consideramos las propiedades topológicas de las órbitas dominantes de los grupos y el papel que desempeñan en el graphlet al que pertenecen. También proponemos revisar las órbitas ausentes en los grupos, es decir, las órbitas ausentes en todos los usuarios del grupo.

Algunas definiciones serán útiles para interpretar el rol que desempeñan las órbitas en un graphlet específico. Es conveniente recordar que cada arista dirigida indica una relación entre dos nodos, donde el nodo inicial representa a un usuario que ha mencionado, respondido o retuiteado al usuario representado por el nodo final. 

\begin{itemize}
    \item Grado de entrada: Para un nodo de un graphlet, el número de arcos dirigidos que comienzan en él se denomina grado de entrada (\textit{indegree}) de $n$. Se denota como $deg-(n)$
    \item Grado de salida: El número de arcos dirigidos que terminan en el nodo de un graphlet es su grado de salida (\textit{outdegree}). Se denota como $deg+(n)$.
    \item Fuente: Un nodo $n$ tal que $deg-(n)=0$. 
    \item Pozo: Un nodo $n$ tal que $deg+(n)=0$.
    \item Camino dirigido en un graphlet: Una secuencia finita de aristas que una secuencia de distintos nodos de tal manera que todas las aristas tenga la misma dirección. Es fácil observar que cada camino maximal en un graphlet comienza en una fuente y termina en un pozo. %Entender bien bien!
\end{itemize}

Dado que el grado de entrada y el grado de salida de un nodo son invariantes bajo un automorfismo, podemos extender las definiciones de fuente y de pozo de los nodos a las órbitas. 

Podemos decir una órbita fuente $\mathcal{O}$ es un oyente (\emph{listener}) si para cada nodo $n\in\mathcal{O}$, la longitud de cada camino maximal que contiene un nodo comenzando en $n$ es igual a 1. Las órbitas 0, 6, 7, 21, 23, y 29 son ejemplos de órbitas de oyentes, pero las órbitas 11 y 17 no lo son. (Ver Fig. \ref{fig:orbits})

De manera similar podemos decir que una órbita pozo $\mathcal{O}$ es un hablante (\emph{speaker}) si para cada nodo  $n\in\mathcal{O}$, $n$ es un pozo con $deg-(n)>1$. Finalmente podemos decir que una órbita $\mathcal{O}$ es una audiencia (\emph{audience}) si para cada nodo $n\in\mathcal{O}$, $n$ es un oyente y cada otro nodo en una arista que comienza en $n$ es un hablante. Las órbitas 7, 21 y 29 son ejemplos de órbitas de audiencia, pero la órbita 23 no lo es. (Ver Fig. \ref{fig:orbits})

Cada nodo en $n$ participa en diferentes graphlets dentro de un red; cada graphlet nos da información sobre su vecindario local de 2, 3, o 4 nodos en los que $n$ participa. Adicionalmente, la información proporcionada por distintos graphlets es diferente a aquella dada únicamente por el $deg-(n)$ o $deg+(n)$. Por ejemplo, es posible distinguir las órbitas 0 y 29 reconociendo que pueden frecuentemente participar en distintos roles dentro de la estructura general de la red, que en en el caso nos permite distinguir entre los perfiles 1 y 2. (Ver Fig. \ref{fig:orbits})

% Sección de estabilidad se va al capítulo de experimentos
\subsection{Estabilidad de los perfiles identificados}

A la similitud entre distintas particiones generadas para un conjunto de datos, la llamaremos la estabilidad de la solución. Mientras más robusta es una estructura de organización en una colección, más parecidos son los agrupamientos resultantes de distintas corridas, con distintas inicializaciones.

Se puede estimar la estabilidad de la solución utilizando la Información Mutua Normalizada (NMI).

La información mutua de dos variables aleatorias mide la dependencia estadística entre ambas variables. Es decir, mide la información o reducción de la incertidumbre (entropía) de una variable aleatoria, $X$, debido al conocimiento del valor de otra variable aleatoria $Y$.

Consideremos dos variables aleatorias $X$ e $Y$ con posibles valores $x_i$, $i=1,2,...,n$, $y_j$, $j=1,2,...,m$ respectivamente. Dónde $$
{\displaystyle P(X=x_{i}|Y=y_{i})=P(x_{i}|y_{j})}$$ y $${\displaystyle P(X=x_{i})=P(x_{i})}$$

De manera formal la Información Mutua está definida como
$$ {\displaystyle I(x_{i};y_{j})=\log {\frac {P(x_{i}|y_{j})}{P(x_{i})}}} $$
y se puede obtener a partir de la entropía que esta definida como
$${\displaystyle H(X)=-\sum _{i}p(x_{i})\log _{2}p(x_{i})}$$
$${\displaystyle H(X,Y)=-\sum _{x,y}p(x,y)\log _{2}p(x,y)}$$
$${\displaystyle H(X|Y)=-\sum _{y}p(y)\sum _{x}p(x|y)\log _{2}p(x|y)}$$

Para obtener la estabilidad de la solución en nuestro problema, corremos el algoritmo de agrupamiento de perfiles $R$ veces y obtenemos el promedio de los valores NMI para cada par de corridas del modelo. Es decir obtenemos una matriz de tamaño $R x R$ donde $C_1,\ldots,C_r$, representan cada $Corrida_i$.

Formalmente, 
\begin{align}\label{eq:PNMI}
Stability(C_1,\ldots,C_r) &= \frac{1}{r(r-1)}\sum_{i,j,i\not=j}^{r}NMI(C_i,C_j) \\
 &= \frac{1}{r(r-1)}\sum_{i,j,i\not=j}^{r} \frac{\mathbb{I}(C_i,C_j)}{\sqrt{{H}(C_i){H}(C_j)}}
\end{align}
donde ${I}(C_i,C_j)$ es la NMI entre corridas $i,j$ y ${H}(C_i)$ denota la entropía de la $i$-ésima asignación.

Tomar en cuenta lo robusto del agrupamiento para diferentes valores iniciales de los centros en el algoritmo de agrupamiento permite estimar la confianza en los perfiles identificados para usuarios considerados en la colección. Esto es importante porque dichos perfiles representan la base de la siguiente fase. 

\section{Agrupar Redes} \label{sec:system:sec3}
La segunda parte de la metodología se centra a agrupar las redes temáticas de la colección. Para ello, utilizamos una representación vectorial basada en los perfiles identificados en la primera parte de nuestro trabajo. De este modo, una vez que los perfiles de usuario se han establecido, creamos un segundo \textit{embedding} a partir de la frecuencia de aparición de cada tipo de usuario en cada una de las redes. 
Nuestra hipótesis es que la frecuencia de aparición de cada perfil de usuario en la red podría variar en función del interés suscitado por un tema y de la naturaleza de la discusión pública (colectiva) en Twitter. Así, cada red es representada por un vector $v$ en ${R}^k$ donde $k$ es el número de perfiles encontrados en el paso anterior y el componente $v_i$ es el conteo de usuarios con el perfil $i$. 

Al representar cada red de acuerdo a la distribución de frecuencia de los tipos de usuario identificados en la fase 1, estamos sugiriendo que un criterio que permite diferenciar las redes en la colección es la dinámica que generan. 

\paragraph{Clustering jerárquico}
Una vez que se tiene la representación vectorial de cada red, utilizamos clustering jerárquico para establecer la comparación entre redes. Este método permite analizar la estructura, en términos de distancia, de los grupos que surgen dentro del conjunto de datos considerando la representación basada en perfiles de usuario. 

En el clustering jerárquico, la estructura, o jerarquía de grupos, se determina de manera avara y comúnmente se presenta en un dendrograma. Además, los resultados dependen de una medida de distancia entre las instancias del conjunto y un criterio de distancia para subconjuntos de datos. 

\begin{figure}[htbp]
  \centering
  \includesvg[width=0.5\textwidth]{figures/hierarchy.svg}
    \caption{Clustering Jerárquico}
    \label{fig:hierarchy}
\end{figure}

Una vez calculada la matriz de distancias entre instancias, los grupos se forman de acuerdo a alguno de los distintos criterios para calcular la distancia $d(s,t)$ entre dos clusters $s$ y $t$; dichos criterios se muestran en la Tabla \ref{tabla:criterios}. El algoritmo que utilizamos, con un enfoque aglomerativo, comienza considerando cada instancia un grupo. En cada paso, la pareja de clústers $s$ y $t$ con mínima distancia entre ellos se unirá para formar un nuevo cluster $u$. El algoritmo termina cuando solo queda un único cluster al que llamamos raíz.

\begin{table}
\caption{{\it Criterios para calcular la distancia entre dos grupos en el agrupamiento jerárquico agolmerativo.}}
\label{tabla:criterios}
    \begin{tabular}{ |p{2cm}|p{11cm}| }
    \hline
    \hline
    Nombre & Función \\
    \hline
        single & $$d(u,v) =  \min(dist(u[i],v[j]))$$ \\
    \hline
        complete & $$d(u, v) = \max(dist(u[i],v[j]))$$  \\
    \hline
        average  & $$d(u,v) = \sum_{ij} \frac{d(u[i], v[j])}{(|u|*|v|)}$$ \\
    \hline
        weighted & $$d(u,v) = \frac{dist(s,v) + dist(t,v) }{2}$$ \\
    \hline
        centroid & $${d(u,v) = \|c_s - c_t\|}_2$$ \\
    \hline
        Ward     & $$d(u,v) = \sqrt{\frac{|v|+|s|}{T}d(v,s)^2+\frac{|v|+|t|}{T}d(v,t)^2- \frac{|v|}{T}d(s,t)^2}$$ dónde $T=|v|+|s|+|t|$ \\
    \hline
    \end{tabular}
\end{table}

%Dados los vectores que representan cada red (embeddings) se calcula la matriz de distancias utilizando la distancia Coseno. La distancia Coseno mide la similitud entre dos vectores en un espacio con producto interior y se mide por el coseno del ángulo entre los dos vectores. Esta distancia se utiliza principalmente cuando la magnitud de los vectores es irrelevante. 

%La distancia coseno es ampliamente utilizada para medir la similitud entre documentos en procesamiento natural del lenguaje \citep{han_data_2012}. En esta tarea un documento se representa como un vector de \textit{término-frecuencia}, este vector se compone por la frecuencia de cada palabra que aparece en el documento y tiene dimensión del conjunto de palabras del documento. Estos vectores son inherentemente \textit{sparse} por lo que las distancias tradicionales no tienen el mejor desempeño \citep{han_data_2012}, es decir pueden existir dos vectores que tengan muchos ceros en común, pero eso no significa que son similares.

%$${\displaystyle {\text{cosine similarity}}=S_{C}(A,B):=\cos(\theta )={\mathbf {A} \cdot \mathbf {B}  \over \|\mathbf {A} \|\|\mathbf {B} \|}={\frac {\sum \limits _{i=1}^{n}{A_{i}B_{i}}}{{\sqrt {\sum \limits _{i=1}^{n}{A_{i}^{2}}}}{\sqrt {\sum \limits _{i=1}^{n}{B_{i}^{2}}}}}},}$$

%Para facilitar el uso de la distancia coseno utilizamos 

%$$ 1 - {\mathbf {A} \cdot \mathbf {B} \over {\|\mathbf {A}\|}_2{\|\mathbf {B}\|}_2}$$

%dónde ${\displaystyle \|{\boldsymbol {x}}\|_{2}$ es la norma euclideana.

Para nuestro problema, la distancia entre instancias se calcula usando la norma L2, definida formalmente como
$${\displaystyle \|{\boldsymbol {x}}\|_{2}:={\sqrt {x_{1}^{2}+\cdots +x_{n}^{2}}}.}$$

\section{Resumen}
La metodología propuesta en este capítulo permite agrupar redes temáticas en Twitter de una forma guiada por los datos, interpretable y basada en el comportamiento que cada tema genera. La Fig. \ref{fig:masterplan} muestra un esquema general del método propuesto. 
 
\begin{figure}[htbp]
   \centering
   \includesvg[width=0.75\textwidth]{figures/plan.svg}
    \caption{Resumen de metodología}
    \label{fig:masterplan}
\end{figure}




